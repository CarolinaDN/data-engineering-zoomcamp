{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380ea2d5-4239-4509-8973-62f802445a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e87257c-7f15-4e76-8999-c0ce9a6d155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/02 16:25:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/08/02 16:25:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ef57dd-fa1f-42d2-8523-d4d8e7eeb519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PySpark 3.4.0 version is running...\n"
     ]
    }
   ],
   "source": [
    "print(f'The PySpark {spark.version} version is running...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7134820-22bd-4dfc-8812-4644ecd24703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-23 21:45:24--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.155.128.46, 18.155.128.6, 18.155.128.187, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.155.128.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 308924937 (295M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘fhvhv_tripdata_2021-01.parquet’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 294.61M   237MB/s    in 1.2s    \n",
      "\n",
      "2024-07-23 21:45:25 (237 MB/s) - ‘fhvhv_tripdata_2021-01.parquet’ saved [308924937/308924937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3c66c8-8f50-4ea9-84b4-215054d42571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006794 fhvhv_tripdata_2021-01.parquet\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5ecc94-af92-4ccd-bd80-3f46ade7428e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('fhvhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1a30db-90ed-4a60-bdd0-6fd5eae2254a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('originating_base_num', StringType(), True), StructField('request_datetime', TimestampType(), True), StructField('on_scene_datetime', TimestampType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropoff_datetime', TimestampType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('trip_miles', DoubleType(), True), StructField('trip_time', LongType(), True), StructField('base_passenger_fare', DoubleType(), True), StructField('tolls', DoubleType(), True), StructField('bcf', DoubleType(), True), StructField('sales_tax', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True), StructField('tips', DoubleType(), True), StructField('driver_pay', DoubleType(), True), StructField('shared_request_flag', StringType(), True), StructField('shared_match_flag', StringType(), True), StructField('access_a_ride_flag', StringType(), True), StructField('wav_request_flag', StringType(), True), StructField('wav_match_flag', StringType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "800a71a5-27a9-4fd6-9244-b4039a20194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d871b8db-fc6c-46b8-a77f-8d2804adfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType(\n",
    "    [types.StructField('hvfhs_license_num', types.StringType(), True),\n",
    "     types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "     types.StructField('originating_base_num', types.StringType(), True),\n",
    "     types.StructField('request_datetime', types.TimestampType(), True),\n",
    "     types.StructField('on_scene_datetime', types.TimestampType(), True),\n",
    "     types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "     types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "     types.StructField('PULocationID', types.IntegerType(), True),\n",
    "     types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "     types.StructField('trip_miles', types.DoubleType(), True),\n",
    "     types.StructField('trip_time', types.LongType(), True),\n",
    "     types.StructField('base_passenger_fare', types.DoubleType(), True),\n",
    "     types.StructField('tolls', types.DoubleType(), True),\n",
    "     types.StructField('bcf', types.DoubleType(), True),\n",
    "     types.StructField('sales_tax', types.DoubleType(), True),\n",
    "     types.StructField('congestion_surcharge', types.DoubleType(), True),\n",
    "     types.StructField('airport_fee', types.DoubleType(), True),\n",
    "     types.StructField('tips', types.DoubleType(), True),\n",
    "     types.StructField('driver_pay', types.DoubleType(), True),\n",
    "     types.StructField('shared_request_flag', types.StringType(), True),\n",
    "     types.StructField('shared_match_flag', types.StringType(), True),\n",
    "     types.StructField('access_a_ride_flag', types.StringType(), True),\n",
    "     types.StructField('wav_request_flag', types.StringType(), True),\n",
    "     types.StructField('wav_match_flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71db43e2-9545-477e-9976-c76cd61af72b",
   "metadata": {},
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .parquet('fhvhv_tripdata_2021-01.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0933a553-07bf-486d-8608-0e78c3236031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lazy command doesn't trigger yet\n",
    "#only when saved it is triggered\n",
    "#expensive operation\n",
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4021a4ce-3b4a-41a4-91cc-8a9967e22524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8154eb92-6e24-45fb-a960-e913f634550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52222394-5d53-4bc3-aa15-9d88c02883d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp (nullable = true)\n",
      " |-- on_scene_datetime: timestamp (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unlike CSV files, parquet files contain the schema of the dataset, so there is no need to specify a schema. You can check the schema like this:\n",
    "# (One of the reasons why parquet files are smaller than CSV files is because they store the data according to the datatypes, so integer values will take less space than long or string values.)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d406a7e-1002-456a-959f-59813dce64ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-11 18:40:22|2021-01-11 19:15:49|         262|         231|\n",
      "|2021-01-05 15:13:22|2021-01-05 15:27:50|          61|         181|\n",
      "|2021-01-31 18:42:09|2021-01-31 18:59:52|         232|           4|\n",
      "|2021-01-27 22:24:36|2021-01-27 22:26:43|          68|          68|\n",
      "|2021-01-30 08:35:46|2021-01-30 08:39:42|         256|         255|\n",
      "|2021-01-16 02:25:35|2021-01-16 02:34:21|          89|          91|\n",
      "|2021-01-11 11:58:23|2021-01-11 12:14:19|          97|          61|\n",
      "|2021-01-03 07:44:58|2021-01-03 08:04:45|          26|         178|\n",
      "|2021-01-14 18:52:00|2021-01-14 19:19:00|         181|         198|\n",
      "|2021-01-08 20:35:35|2021-01-08 21:06:33|          76|          91|\n",
      "|2021-01-15 13:49:48|2021-01-15 14:35:23|         246|          16|\n",
      "|2021-01-27 10:37:56|2021-01-27 10:53:35|         135|          73|\n",
      "|2021-01-11 17:29:44|2021-01-11 17:42:49|          68|         211|\n",
      "|2021-01-24 21:32:15|2021-01-24 21:52:42|         249|         236|\n",
      "|2021-01-26 18:03:39|2021-01-26 18:10:53|          79|           4|\n",
      "|2021-01-07 08:05:32|2021-01-07 08:30:47|          22|          25|\n",
      "|2021-01-12 17:16:00|2021-01-12 17:25:56|          69|         119|\n",
      "|2021-01-16 21:00:39|2021-01-16 21:18:15|         239|         239|\n",
      "|2021-01-14 23:35:14|2021-01-14 23:45:30|          61|          62|\n",
      "|2021-01-17 23:23:11|2021-01-17 23:34:42|         241|          20|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#only executes when we do .show\n",
    "\n",
    "#similar to: SELECT * FROM df WHERE hvfhs_license_num = HV0003\n",
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "  .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4cf437-c6ee-4ca1-a76e-f5167244601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6289aebc-674f-47fb-98a3-24c1370cf2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new function\n",
    "#Besides these built-in functions, Spark allows us to create User Defined Functions (UDFs) with custom behavior for those instances where creating SQL queries for that behaviour becomes difficult both to manage and test.\n",
    "#UDFs are regular functions which are then passed as parameters to a special builder. Let's create one:\n",
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddbfed90-5e57-48b0-b324-59404d7652c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s/b44'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crazy_stuff('B02884')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec20deab-6641-45fc-aa85-e246db0567cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b356484-8647-4afc-bd6b-a8eaac59ea7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|pickup_date|dropoff_date|\n",
      "+-----------+------------+\n",
      "| 2021-01-11|  2021-01-11|\n",
      "| 2021-01-05|  2021-01-05|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-31|  2021-01-31|\n",
      "| 2021-01-05|  2021-01-05|\n",
      "| 2021-01-27|  2021-01-27|\n",
      "| 2021-01-18|  2021-01-18|\n",
      "| 2021-01-30|  2021-01-30|\n",
      "| 2021-01-16|  2021-01-16|\n",
      "| 2021-01-05|  2021-01-05|\n",
      "| 2021-01-11|  2021-01-11|\n",
      "| 2021-01-22|  2021-01-22|\n",
      "| 2021-01-03|  2021-01-03|\n",
      "| 2021-01-14|  2021-01-14|\n",
      "| 2021-01-08|  2021-01-08|\n",
      "| 2021-01-15|  2021-01-15|\n",
      "| 2021-01-27|  2021-01-27|\n",
      "| 2021-01-18|  2021-01-18|\n",
      "| 2021-01-11|  2021-01-11|\n",
      "| 2021-01-24|  2021-01-24|\n",
      "+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adding two new columns\n",
    "#if giving column name that already exists -> overwrite\n",
    "\n",
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .select('pickup_date', 'dropoff_date') \\\n",
    "    .show()\n",
    "\n",
    "#    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd853f86-122c-4086-9564-0c15d5cf77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "    .select('base_id', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43f2a0-5f50-491b-ab66-cbe6d0679199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8123e0a-2cc4-4c5c-b3f5-48df7e382362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow.parquet import ParquetFile\n",
    "pf = ParquetFile('fhvhv_tripdata_2021-01.parquet')\n",
    "#pyarrow builds tables, not dataframes\n",
    "tbl_small = next(pf.iter_batches(batch_size = 1000))\n",
    "#this function converts the table to a dataframe of manageable size\n",
    "df_small = tbl_small.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b593cb1-e0a7-4f42-a8ec-115908dacc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02682</td>\n",
       "      <td>B02682</td>\n",
       "      <td>2021-01-01 00:28:09</td>\n",
       "      <td>2021-01-01 00:31:42</td>\n",
       "      <td>2021-01-01 00:33:44</td>\n",
       "      <td>2021-01-01 00:49:07</td>\n",
       "      <td>230</td>\n",
       "      <td>166</td>\n",
       "      <td>5.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.99</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02682</td>\n",
       "      <td>B02682</td>\n",
       "      <td>2021-01-01 00:45:56</td>\n",
       "      <td>2021-01-01 00:55:19</td>\n",
       "      <td>2021-01-01 00:55:19</td>\n",
       "      <td>2021-01-01 01:18:21</td>\n",
       "      <td>152</td>\n",
       "      <td>167</td>\n",
       "      <td>3.65</td>\n",
       "      <td>...</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.06</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-01-01 00:21:15</td>\n",
       "      <td>2021-01-01 00:22:41</td>\n",
       "      <td>2021-01-01 00:23:56</td>\n",
       "      <td>2021-01-01 00:38:05</td>\n",
       "      <td>233</td>\n",
       "      <td>142</td>\n",
       "      <td>3.51</td>\n",
       "      <td>...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94</td>\n",
       "      <td>12.98</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-01-01 00:39:12</td>\n",
       "      <td>2021-01-01 00:42:37</td>\n",
       "      <td>2021-01-01 00:42:51</td>\n",
       "      <td>2021-01-01 00:45:50</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.41</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-01-01 00:46:11</td>\n",
       "      <td>2021-01-01 00:47:17</td>\n",
       "      <td>2021-01-01 00:48:14</td>\n",
       "      <td>2021-01-01 01:08:42</td>\n",
       "      <td>143</td>\n",
       "      <td>78</td>\n",
       "      <td>9.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.44</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0            HV0003               B02682               B02682   \n",
       "1            HV0003               B02682               B02682   \n",
       "2            HV0003               B02764               B02764   \n",
       "3            HV0003               B02764               B02764   \n",
       "4            HV0003               B02764               B02764   \n",
       "\n",
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2021-01-01 00:28:09 2021-01-01 00:31:42 2021-01-01 00:33:44   \n",
       "1 2021-01-01 00:45:56 2021-01-01 00:55:19 2021-01-01 00:55:19   \n",
       "2 2021-01-01 00:21:15 2021-01-01 00:22:41 2021-01-01 00:23:56   \n",
       "3 2021-01-01 00:39:12 2021-01-01 00:42:37 2021-01-01 00:42:51   \n",
       "4 2021-01-01 00:46:11 2021-01-01 00:47:17 2021-01-01 00:48:14   \n",
       "\n",
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n",
       "0 2021-01-01 00:49:07           230           166        5.26  ...       1.98   \n",
       "1 2021-01-01 01:18:21           152           167        3.65  ...       1.63   \n",
       "2 2021-01-01 00:38:05           233           142        3.51  ...       1.25   \n",
       "3 2021-01-01 00:45:50           142           143        0.74  ...       0.70   \n",
       "4 2021-01-01 01:08:42           143            78        9.20  ...       2.41   \n",
       "\n",
       "   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n",
       "0                  2.75          NaN  0.00       14.99                    N   \n",
       "1                  0.00          NaN  0.00       17.06                    N   \n",
       "2                  2.75          NaN  0.94       12.98                    N   \n",
       "3                  2.75          NaN  0.00        7.41                    N   \n",
       "4                  2.75          NaN  0.00       22.44                    N   \n",
       "\n",
       "   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n",
       "0                  N                                     N              N  \n",
       "1                  N                                     N              N  \n",
       "2                  N                                     N              N  \n",
       "3                  N                                     N              N  \n",
       "4                  N                                     N              N  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e33e31a6-95d0-434d-9582-8458fec3ee08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num               object\n",
       "dispatching_base_num            object\n",
       "originating_base_num            object\n",
       "request_datetime        datetime64[ns]\n",
       "on_scene_datetime       datetime64[ns]\n",
       "pickup_datetime         datetime64[ns]\n",
       "dropoff_datetime        datetime64[ns]\n",
       "PULocationID                     int64\n",
       "DOLocationID                     int64\n",
       "trip_miles                     float64\n",
       "trip_time                        int64\n",
       "base_passenger_fare            float64\n",
       "tolls                          float64\n",
       "bcf                            float64\n",
       "sales_tax                      float64\n",
       "congestion_surcharge           float64\n",
       "airport_fee                    float64\n",
       "tips                           float64\n",
       "driver_pay                     float64\n",
       "shared_request_flag             object\n",
       "shared_match_flag               object\n",
       "access_a_ride_flag              object\n",
       "wav_request_flag                object\n",
       "wav_match_flag                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a328d2f3-3a08-4977-bb5c-ba2d4036cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 100 fhvhv_tripdata_2021-01.parquet > head.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7574c-6b3f-435a-a7ce-8446a5592e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
