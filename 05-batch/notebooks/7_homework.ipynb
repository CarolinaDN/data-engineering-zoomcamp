{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d06c705-f8bf-4fed-98fc-40dc5c16be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee24e02f-78a0-41bb-95a3-99b51fe12584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/05 11:52:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd12bf-a0c5-49f9-8fa1-f8b5a9e167a7",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "\n",
    "Install Spark and PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4f8921-f439-4bd4-8a6f-d4497c58a5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PySpark 3.4.0 version is running...\n"
     ]
    }
   ],
   "source": [
    "print(f'The PySpark {spark.version} version is running...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdcb4d1-cc0f-4b76-9128-3188d9d73978",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "\n",
    "Read FHV October 2019\n",
    "\n",
    "Repartition the Dataframe and save it to parquet.\n",
    "\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? 33MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8872085-cdd3-457b-a5af-5e9770616c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet(\"fhvhv_tripdata_2021-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb09bdb0-d2da-4032-9a26-71c0bd9213b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime=datetime.datetime(2021, 1, 31, 23, 59), on_scene_datetime=datetime.datetime(2021, 2, 1, 0, 10, 19), pickup_datetime=datetime.datetime(2021, 2, 1, 0, 10, 40), dropoff_datetime=datetime.datetime(2021, 2, 1, 0, 21, 9), PULocationID=35, DOLocationID=39, trip_miles=2.06, trip_time=629, base_passenger_fare=17.14, tolls=0.0, bcf=0.51, sales_tax=1.52, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=9.79, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fe0749b-a126-4bbb-b6a7-be35920c19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b296e1e6-cd7e-4a60-8b3d-64ea3379b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('data/pq/fhvhv/2021/02/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00ff0db-2525-4f8f-8c98-9812bbe59b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('data/pq/fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c03a87-ae2d-4998-a821-375c99005c1e",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "How many taxi trips were there on February 15?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "019303e1-711f-4eac-8abe-bd1a3d3ba654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrong way\n",
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .filter(df.pickup_datetime == '2021-02-15') \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1cd917d-b316-4949-9d73-fdae65d14778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "367170"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .filter(\"pickup_date = '2021-02-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c0f99d5-7ae7-4992-8c9d-4782597e5a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carolina/spark/spark-3.4.0-bin-hadoop3/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('fhvhv_2021_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c309b292-e3a4-453c-a777-8e41af5babb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  367170|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhvhv_2021_02\n",
    "WHERE\n",
    "    to_date(pickup_datetime) = '2021-02-15';\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11bece-95d2-4723-9f75-de172f27d14b",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "Longest trip for each day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70f9b3e9-eb61-4447-bc77-016d1b1fe41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|pickup_date|max(trip_time)|\n",
      "+-----------+--------------+\n",
      "| 2021-02-11|         75540|\n",
      "| 2021-02-17|         57220|\n",
      "| 2021-02-20|         44038|\n",
      "| 2021-02-03|         40653|\n",
      "| 2021-02-19|         37577|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .groupBy('pickup_date') \\\n",
    "        .max('trip_time') \\\n",
    "    .orderBy('max(trip_time)', ascending=False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3cfde40-bc3d-4d4a-b6f0-5c0384ad3acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|pickup_date|day_trip_time|\n",
      "+-----------+-------------+\n",
      "| 2021-02-11|        75540|\n",
      "| 2021-02-17|        57220|\n",
      "| 2021-02-20|        44038|\n",
      "| 2021-02-03|        40653|\n",
      "| 2021-02-19|        37577|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    to_date(pickup_datetime) AS pickup_date,\n",
    "    MAX(trip_time) as day_trip_time\n",
    "FROM \n",
    "    fhvhv_2021_02\n",
    "GROUP BY\n",
    "    pickup_date\n",
    "ORDER BY\n",
    "    day_trip_time DESC\n",
    "LIMIT\n",
    "    5\n",
    ";\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fbf12-252e-4d69-b639-51d4e1728d13",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "Most frequent dispatching_base_num\n",
    "\n",
    "How many stages this spark job has? 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07fe4651-d275-46a5-a49a-f3cc3d55308e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|  count|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .groupBy('dispatching_base_num') \\\n",
    "        .count() \\\n",
    "    .orderBy('count', ascending=False) \\\n",
    "    .limit(1) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a339df50-88aa-463c-90cc-9b2b29e665f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|   freq|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "|              B02764| 965568|\n",
      "|              B02872| 882689|\n",
      "|              B02875| 685390|\n",
      "|              B02765| 559768|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    dispatching_base_num,\n",
    "    COUNT(1) as freq\n",
    "FROM \n",
    "    fhvhv_2021_02\n",
    "GROUP BY\n",
    "    dispatching_base_num\n",
    "ORDER BY\n",
    "    freq DESC\n",
    "LIMIT\n",
    "    5\n",
    ";\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1001eef8-e9cc-4935-a98d-1c1e65f0dd16",
   "metadata": {},
   "source": [
    "### Question 6:\n",
    "Most common locations pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29a6e7ea-7f17-4172-8149-f499525a8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfbc2375-feb9-4b75-bf16-48fc743ad055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(LocationID='1', Borough='EWR', Zone='Newark Airport', service_zone='EWR')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71d3ea12-15fd-4f34-8b66-3f4574186f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "893e6601-e159-4ec8-bf32-26eb0b083301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          pu_do_pair| freq|\n",
      "+--------------------+-----+\n",
      "|East New York / E...|45041|\n",
      "|Borough Park / Bo...|37329|\n",
      "| Canarsie / Canarsie|28026|\n",
      "|Crown Heights Nor...|25976|\n",
      "|Bay Ridge / Bay R...|17934|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    CONCAT(pul.Zone, ' / ', dol.Zone) AS pu_do_pair,\n",
    "    COUNT(1) as freq\n",
    "FROM \n",
    "    fhvhv_2021_02 as fhv LEFT JOIN zones as pul ON fhv.PULocationID = pul.LocationID\n",
    "                         LEFT JOIN zones dol ON fhv.DOLocationID = dol.LocationID\n",
    "GROUP BY \n",
    "    pu_do_pair\n",
    "ORDER BY\n",
    "    freq DESC\n",
    "LIMIT 5;\n",
    "\"\"\").show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
